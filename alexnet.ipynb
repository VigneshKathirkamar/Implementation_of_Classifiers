{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55cdf9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72c0b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdaa5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 227\n",
    "image_height = 227\n",
    "image_channel = 3\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf31d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this block we will define Alexnet\n",
    "\n",
    "def Alexnet():\n",
    "    model = tf.keras.Sequential([\n",
    "        # layer 1\n",
    "        tf.keras.layers.Conv2D(filters=96,\n",
    "                               kernel_size=(11,11),\n",
    "                               strides=4,\n",
    "                               padding=\"valid\",\n",
    "                               activation=tf.keras.activations.relu,\n",
    "                               input_shape=(image_height,image_width,image_channel)),\n",
    "        \n",
    "        tf.keras.layers.MaxPool2D(pool_size=(3,3),\n",
    "                                  strides=2,\n",
    "                                  padding=\"valid\"),\n",
    "        \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "        # layer 2\n",
    "        tf.keras.layers.Conv2D(filters=256,\n",
    "                               kernel_size=(5,5),\n",
    "                               strides=1,padding=\"same\",\n",
    "                               activation=tf.keras.activations.relu),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(3,3),\n",
    "                                  strides=2,\n",
    "                                  padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # layer 3\n",
    "        tf.keras.layers.Conv2D(filters=384,\n",
    "                               kernel_size=(3,3),\n",
    "                               strides=1,\n",
    "                               padding=\"same\",\n",
    "                               activation=tf.keras.activations.relu),\n",
    "        \n",
    "        # layer 4\n",
    "        tf.keras.layers.Conv2D(filters=256,\n",
    "                               kernel_size=(3,3),\n",
    "                               strides=1,\n",
    "                               padding=\"same\",\n",
    "                               activation=tf.keras.activations.relu),\n",
    "        \n",
    "        # layer 5\n",
    "        tf.keras.layers.Conv2D(filters=256,\n",
    "                               kernel_size=(3,3),\n",
    "                               strides=1,\n",
    "                               padding=\"same\",\n",
    "                               activation=tf.keras.activations.relu),\n",
    "        \n",
    "        tf.keras.layers.MaxPool2D(pool_size=(3,3),\n",
    "                           strides=1,\n",
    "                           padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # layer 6\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=4096,\n",
    "                              activation=tf.keras.activations.relu),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # layer 7\n",
    "        tf.keras.layers.Dense(units=4096,\n",
    "                              activation=tf.keras.activations.relu),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # layer 8\n",
    "        tf.keras.layers.Dense(units=NUM_CLASSES,\n",
    "                              activation=tf.keras.activations.softmax)\n",
    "        ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e3bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def make_dataset():\n",
    "    \n",
    "    training_dir = \"/home/vignesh/fish/fishes/train/\" \n",
    "    test_dir = \"/home/vignesh/fish/fishes/test/\"\n",
    "    validation_dir = \"/home/vignesh/fish/fishes/validation/\"\n",
    "    image_width = 227\n",
    "    image_height = 227\n",
    "    image_channel = 3\n",
    "    BATCH_SIZE = 8\n",
    "    train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
    "    training_generator = train_data_gen.flow_from_directory(training_dir,\n",
    "                                                        target_size=(image_height,image_width),\n",
    "                                                        batch_size=BATCH_SIZE,\n",
    "                                                         seed = 7,\n",
    "                                                         shuffle = True,\n",
    "                                                         class_mode = \"categorical\")\n",
    "    validation_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
    "    validation_generator = validation_data_gen.flow_from_directory(validation_dir,\n",
    "                                                            target_size=(image_height,image_width),\n",
    "                                                             color_mode=\"rgb\",\n",
    "                                                             batch_size = BATCH_SIZE,\n",
    "                                                             seed = 7,\n",
    "                                                             shuffle = True,\n",
    "                                                             class_mode = \"categorical\"\n",
    "                                                            )\n",
    "\n",
    "    testing_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
    "    testing_generator = testing_data_gen.flow_from_directory(test_dir,\n",
    "                                                             target_size=(image_height,image_width),\n",
    "                                                             color_mode = \"rgb\",\n",
    "                                                             batch_size = BATCH_SIZE,\n",
    "                                                             seed = 7,\n",
    "                                                             shuffle = True,\n",
    "                                                             class_mode = \"categorical\")\n",
    "  \n",
    "\n",
    "    train_num = training_generator.samples\n",
    "    valid_num = validation_generator.samples\n",
    "    test_num = testing_generator.samples\n",
    "\n",
    "\n",
    "    return training_generator, \\\n",
    "           validation_generator, \\\n",
    "           testing_generator, \\\n",
    "           train_num, valid_num, test_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa949063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1929 images belonging to 2 classes.\n",
      "Found 57 images belonging to 2 classes.\n",
      "Found 106 images belonging to 2 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 256)       884992    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              205524992 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 225,326,722\n",
      "Trainable params: 225,325,506\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "241/241 [==============================] - 108s 405ms/step - loss: 6.4647 - accuracy: 0.8771 - val_loss: 3.3587 - val_accuracy: 0.7368\n",
      "Epoch 2/2\n",
      "241/241 [==============================] - 94s 389ms/step - loss: 0.6532 - accuracy: 0.9386 - val_loss: 9.0210 - val_accuracy: 0.6140\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "############################################################\n",
    "# required configurations\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 2\n",
    "model_dir = \"image_classification_model.h5\"\n",
    "# training_dir =\"/home/vignesh/fish/fishes/train\"\n",
    "# testing_dir = \"/home/vignesh/fish/fishes/test\"\n",
    "# validation_dir = \"/home/vignesh/fish/fishes/validation\"\n",
    "###########################################################\n",
    "\n",
    "def get_model():\n",
    "    model = Alexnet()\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "training_generator, validation_generator, testing_generator,train_num, valid_num, test_num = make_dataset()\n",
    "\n",
    "# Use command tensorboard --logdir \"log\" to start tensorboard\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='log')\n",
    "callback_list = [tensorboard]\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n",
    "\n",
    "# start training\n",
    "model.fit(training_generator,epochs=EPOCHS,steps_per_epoch=train_num//BATCH_SIZE,callbacks=callback_list, validation_data=validation_generator)\n",
    "\n",
    "# save the whole model\n",
    "model.save(model_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d352369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad48ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca63f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
